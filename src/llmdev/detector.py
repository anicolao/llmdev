"""
Copilot detection heuristics and pattern matching.
"""

import re
import logging
from typing import Dict, List, Optional, Set
from dataclasses import dataclass


logger = logging.getLogger(__name__)


@dataclass
class Detection:
    """Represents a Copilot detection result."""

    source_type: str  # 'commit', 'pr', 'issue'
    source_id: str
    detection_type: str
    confidence: float  # 0.0 to 1.0
    evidence: str
    metadata: Dict = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


class CopilotDetector:
    """Detect Copilot-generated code and mentions."""

    # Keywords that indicate Copilot usage
    COPILOT_KEYWORDS = [
        "copilot",
        "co-pilot",
        "github copilot",
        "gh copilot",
        "generated by copilot",
        "using copilot",
        "with copilot",
    ]

    # Bot usernames that might be Copilot-related
    BOT_PATTERNS = [
        r"copilot",
        r"github-copilot",
    ]

    def __init__(self):
        """Initialize the detector."""
        self.detections: List[Detection] = []

    def detect_in_text(
        self, text: str, source_type: str, source_id: str, case_sensitive: bool = False
    ) -> List[Detection]:
        """
        Detect Copilot mentions in text.

        Args:
            text: Text to search
            source_type: Type of source ('commit', 'pr', 'issue')
            source_id: Identifier for the source
            case_sensitive: Whether to use case-sensitive matching

        Returns:
            List of Detection objects
        """
        if not text:
            return []

        detections = []
        search_text = text if case_sensitive else text.lower()

        for keyword in self.COPILOT_KEYWORDS:
            search_keyword = keyword if case_sensitive else keyword.lower()
            if search_keyword in search_text:
                # Find the context around the keyword
                pattern = re.compile(
                    f".{{0,50}}{re.escape(search_keyword)}.{{0,50}}",
                    re.IGNORECASE if not case_sensitive else 0,
                )
                matches = pattern.findall(text)

                for match in matches:
                    detections.append(
                        Detection(
                            source_type=source_type,
                            source_id=source_id,
                            detection_type="explicit_mention",
                            confidence=0.95,
                            evidence=match.strip(),
                            metadata={"keyword": keyword},
                        )
                    )
                break  # Only count once per text

        return detections

    def detect_in_commit(self, commit_data: Dict) -> List[Detection]:
        """
        Detect Copilot usage in a commit.

        Args:
            commit_data: Dictionary with commit information

        Returns:
            List of Detection objects
        """
        detections = []
        commit_id = commit_data.get("sha", "unknown")

        # Check commit message
        message = commit_data.get("message", "")
        detections.extend(self.detect_in_text(message, "commit", commit_id))

        # Check author
        author = commit_data.get("author", "")
        if author and self._is_bot_author(author):
            detections.append(
                Detection(
                    source_type="commit",
                    source_id=commit_id,
                    detection_type="bot_author",
                    confidence=0.8,
                    evidence=f"Author: {author}",
                    metadata={"author": author},
                )
            )

        return detections

    def detect_in_pr(self, pr_data: Dict) -> List[Detection]:
        """
        Detect Copilot mentions in a pull request.

        Args:
            pr_data: Dictionary with PR information

        Returns:
            List of Detection objects
        """
        detections = []
        pr_id = str(pr_data.get("number", "unknown"))

        # Check PR title
        title = pr_data.get("title", "")
        detections.extend(self.detect_in_text(title, "pr", pr_id))

        # Check PR body/description
        body = pr_data.get("body", "")
        detections.extend(self.detect_in_text(body, "pr", pr_id))

        # Check comments
        for comment in pr_data.get("comments", []):
            comment_body = comment.get("body", "")
            detections.extend(self.detect_in_text(comment_body, "pr", pr_id))

        return detections

    def detect_in_issue(self, issue_data: Dict) -> List[Detection]:
        """
        Detect Copilot mentions in an issue.

        Args:
            issue_data: Dictionary with issue information

        Returns:
            List of Detection objects
        """
        detections = []
        issue_id = str(issue_data.get("number", "unknown"))

        # Check issue title
        title = issue_data.get("title", "")
        detections.extend(self.detect_in_text(title, "issue", issue_id))

        # Check issue body/description
        body = issue_data.get("body", "")
        detections.extend(self.detect_in_text(body, "issue", issue_id))

        # Check comments
        for comment in issue_data.get("comments", []):
            comment_body = comment.get("body", "")
            detections.extend(self.detect_in_text(comment_body, "issue", issue_id))

        return detections

    def _is_bot_author(self, author: str) -> bool:
        """
        Check if an author name matches bot patterns.

        Args:
            author: Author name to check

        Returns:
            True if the author appears to be a bot
        """
        author_lower = author.lower()
        for pattern in self.BOT_PATTERNS:
            if re.search(pattern, author_lower):
                return True
        return False

    def get_summary(self, detections: List[Detection]) -> Dict:
        """
        Generate a summary of detections.

        Args:
            detections: List of Detection objects

        Returns:
            Dictionary with summary statistics
        """
        if not detections:
            return {"total": 0, "by_source": {}, "by_type": {}, "average_confidence": 0.0}

        by_source = {}
        by_type = {}
        total_confidence = 0.0

        for detection in detections:
            # Count by source type
            by_source[detection.source_type] = by_source.get(detection.source_type, 0) + 1

            # Count by detection type
            by_type[detection.detection_type] = by_type.get(detection.detection_type, 0) + 1

            # Sum confidence
            total_confidence += detection.confidence

        return {
            "total": len(detections),
            "by_source": by_source,
            "by_type": by_type,
            "average_confidence": total_confidence / len(detections) if detections else 0.0,
        }
